{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col,udf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "import s3fs\n",
    "import string\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from boto.s3.connection import S3Connection\n",
    "import re\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk-pom:1.11.115,org.apache.hadoop:hadoop-aws:2.7.2 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setMaster(\"local\").setAppName(\"twitter\")\n",
    "sc=SparkContext(conf=conf)\n",
    "\n",
    "sqlContext = SQLContext (sc)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "sc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"AKIAJJDTKJ6JYJDVCHBA\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\",\"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\")\n",
    "fs = s3fs.S3FileSystem(anon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctuation(column):\n",
    "    return trim(lower(regexp_replace(column, '[^\\sa-zA-Z0-9]', '')))\n",
    "\n",
    "#Replace turkish characters\n",
    "def ReplaceTurkishCharsFunc(column):\n",
    "    column=regexp_replace(column, 'İ', 'i')\n",
    "    column=regexp_replace(column, 'ı', 'i')\n",
    "    column=regexp_replace(column, 'Ö', 'o')\n",
    "    column=regexp_replace(column, 'ö', 'o')\n",
    "    column=regexp_replace(column, 'Ç', 'c')\n",
    "    column=regexp_replace(column, 'ç', 'c')\n",
    "    column=regexp_replace(column, 'Ş', 's')\n",
    "    column=regexp_replace(column, 'ş', 's')\n",
    "    \n",
    "    column=regexp_replace(column, 'ğ', 'g')\n",
    "    column=regexp_replace(column, 'Ğ', 'g')\n",
    "    \n",
    "    column=regexp_replace(column, 'ü', 'u')\n",
    "    column=regexp_replace(column, 'Ü', 'u')\n",
    "    column=regexp_replace(column, '0xC4', 'XX')\n",
    "    column=regexp_replace(column, 'xfc', 'XX')\n",
    "    column=regexp_replace(column, '\\n', ' ')\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Schema\n",
    "dfsc = sqlContext.read.json(\"/home/ubuntu/Schema_v1.json\")\n",
    "schema_json = dfsc.schema.json()\n",
    "new_schema = StructType.fromJson(json.loads(schema_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(created_at='Mon May 28 23:58:41 +0000 2018', id=1001251446778728448, id_str='1001251446778728448', lang='tr', retweet_count=335, retweeted=False, retweeted_status=Row(id=1000692311330840576, id_str='1000692311330840576'), text='RT @EnesAkenes: Chp\\'ye OY YOK\\n\"Nankör olanın gözü çıksıınn..\\nOyum TAYYİP\\'E\" diyor \\n\\nAblanın sebeplerini\\nİZLEYİN...!!!\\n#27Mayıs\\n#MutluPazarl…')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Twitter file path\n",
    "fname=\"Tweets1.json\"\n",
    "#Output file name for cleaned text tweets\n",
    "#fnameO='s3://twitterdataelection/TweetCleanData.txt'\n",
    "#Read file from json file with the specific schema\n",
    "jsonf = sqlContext.read.option(\"encoding\", \"utf-8\").json(fname,schema=new_schema)\n",
    "jsonf=jsonf.dropDuplicates()\n",
    "jsonf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- id_str: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- retweeted_status: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(tcreated_at='Mon May 28 23:58:41 +0000 2018', tid=1001251446778728448, tid_str='1001251446778728448', lang='tr', retweet_count=335, retweeted=False, text='RT @EnesAkenes: Chp\\'ye OY YOK\\n\"Nankör olanın gözü çıksıınn..\\nOyum TAYYİP\\'E\" diyor \\n\\nAblanın sebeplerini\\nİZLEYİN...!!!\\n#27Mayıs\\n#MutluPazarl…', id=1000692311330840576, id_str='1000692311330840576')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Flatten the retweeted_status struct\n",
    "jsonf2=jsonf.select( col(\"created_at\").alias(\"tcreated_at\"), col(\"id\").alias(\"tid\"), col(\"id_str\").alias(\"tid_str\"),\"lang\"  , \"retweet_count\",\"retweeted\" ,\"text\", \"retweeted_status.*\")\n",
    "jsonf2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tcreated_at: string (nullable = true)\n",
      " |-- tid: long (nullable = true)\n",
      " |-- tid_str: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- id_str: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonf2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(tcreated_at='Mon May 28 23:58:41 +0000 2018', tid=1001251446778728448, tid_str='1001251446778728448', lang='tr', retweet_count=335, retweeted=False, text='RT @EnesAkenes: Chp\\'ye OY YOK \"Nankor olanin gozu ciksiinn.. Oyum TAYYiP\\'E\" diyor   Ablanin sebeplerini iZLEYiN...!!! #27Mayis #MutluPazarl…', rtid=1000692311330840576, rtid_str='1000692311330840576')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonf3=jsonf2.select( \"tcreated_at\", \"tid\", \"tid_str\",\"lang\" ,\"retweet_count\" ,\"retweeted\", ReplaceTurkishCharsFunc(col(\"text\")).alias(\"text\"), col(\"id\").alias(\"rtid\"),col(\"id_str\").alias(\"rtid_str\"))\n",
    "jsonf3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tcreated_at: string (nullable = true)\n",
      " |-- tid: long (nullable = true)\n",
      " |-- tid_str: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- rtid: long (nullable = true)\n",
      " |-- rtid_str: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonf3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(tcreated_at='Mon May 28 23:58:41 +0000 2018', tid=1001251446778728448, tid_str='1001251446778728448', lang='tr', retweet_count=335, retweeted=False, text='rt enesakenes chpye oy yok nankor olanin gozu ciksiinn oyum tayyipe diyor   ablanin sebeplerini izleyin 27mayis mutlupazarl', rtid=1000692311330840576, rtid_str='1000692311330840576')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonf4=jsonf3.select( \"tcreated_at\", \"tid\", \"tid_str\",\"lang\" ,\"retweet_count\" ,\"retweeted\", removePunctuation(col(\"text\")).alias(\"text\"), \"rtid\",\"rtid_str\")\n",
    "jsonf4.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tcreated_at: string (nullable = true)\n",
      " |-- tid: long (nullable = true)\n",
      " |-- tid_str: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- rtid: long (nullable = true)\n",
      " |-- rtid_str: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonf4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcreated_at</th>\n",
       "      <th>tid</th>\n",
       "      <th>tid_str</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "      <th>rtid</th>\n",
       "      <th>rtid_str</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon May 28 23:58:41 +0000 2018</td>\n",
       "      <td>1.001251e+18</td>\n",
       "      <td>1001251446778728448</td>\n",
       "      <td>tr</td>\n",
       "      <td>335.0</td>\n",
       "      <td>False</td>\n",
       "      <td>rt enesakenes chpye oy yok nankor olanin gozu ...</td>\n",
       "      <td>1.000692e+18</td>\n",
       "      <td>1000692311330840576</td>\n",
       "      <td>Tweets1.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tcreated_at           tid              tid_str lang  \\\n",
       "0  Mon May 28 23:58:41 +0000 2018  1.001251e+18  1001251446778728448   tr   \n",
       "\n",
       "   retweet_count retweeted                                               text  \\\n",
       "0          335.0     False  rt enesakenes chpye oy yok nankor olanin gozu ...   \n",
       "\n",
       "           rtid             rtid_str         fname  \n",
       "0  1.000692e+18  1000692311330840576  Tweets1.json  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add file name to dataframe\n",
    "jsonf5=jsonf4.withColumn(\"fname\", lit(fname))\n",
    "#Convert to Pandas Dataframe\n",
    "dfP=jsonf5.toPandas()\n",
    "dfP.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add lenghth of tweets \n",
    "dfP['TLength'] = dfP['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcreated_at</th>\n",
       "      <th>tid</th>\n",
       "      <th>tid_str</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "      <th>rtid</th>\n",
       "      <th>rtid_str</th>\n",
       "      <th>fname</th>\n",
       "      <th>TLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon May 28 23:58:41 +0000 2018</td>\n",
       "      <td>1.001251e+18</td>\n",
       "      <td>1001251446778728448</td>\n",
       "      <td>tr</td>\n",
       "      <td>335.0</td>\n",
       "      <td>False</td>\n",
       "      <td>rt enesakenes chpye oy yok nankor olanin gozu ...</td>\n",
       "      <td>1.000692e+18</td>\n",
       "      <td>1000692311330840576</td>\n",
       "      <td>Tweets1.json</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tcreated_at           tid              tid_str lang  \\\n",
       "0  Mon May 28 23:58:41 +0000 2018  1.001251e+18  1001251446778728448   tr   \n",
       "\n",
       "   retweet_count retweeted                                               text  \\\n",
       "0          335.0     False  rt enesakenes chpye oy yok nankor olanin gozu ...   \n",
       "\n",
       "           rtid             rtid_str         fname  TLength  \n",
       "0  1.000692e+18  1000692311330840576  Tweets1.json    123.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfP.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Number of Words in Tweets\n",
    "dfP['TWCount']=dfP['text'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averages and Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght's average in tweets: 116.88597537282435\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mean = np.mean(dfP['TLength'])\n",
    "\n",
    "print(\"The lenght's average in tweets: {}\".format(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avarage of word that are used in tweets: 16.754540521347653\n"
     ]
    }
   ],
   "source": [
    "meanw = np.mean(dfP['TWCount'])\n",
    "\n",
    "print(\"The avarage of word that are used in tweets: {}\".format(meanw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joint Plot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "    \n",
    "x =dfP['TLength']\n",
    "y =dfP['TWCount']\n",
    "data = pd.DataFrame({\n",
    "    'Character Length of Tweets': x,\n",
    "    'Used Word Count of Tweets': y,\n",
    "})\n",
    "\n",
    "sns.jointplot(x='Character Length of Tweets', y='Used Word Count of Tweets', data=data, kind='reg',height=8,color=\"violet\").plot_joint(sns.kdeplot, zorder=0, n_levels=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweet with more RT: \n",
      "rt btstwt   httpstcooz32cjdru8\n",
      "Number of likes: 324835.0\n",
      "30.0 characters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_RetweetCount = np.max(dfP['retweet_count'])\n",
    "fav = dfP[dfP.retweet_count == max_RetweetCount].index[0]\n",
    "print(\"The tweet with more RT: \\n{}\".format(dfP['text'][fav]))\n",
    "print(\"Number of likes: {}\".format(max_RetweetCount))\n",
    "print(\"{} characters.\\n\".format(dfP['TLength'][fav]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tr', 'tl', 'und', 'es', 'de', 'en', 'in', 'pl', 'fr', 'ja', 'it',\n",
       "       'pt', 'hu', 'th', 'eu', 'ro', 'ko', 'et', 'lt', 'sl', 'cs', 'cy',\n",
       "       'is', 'hi', 'ht', 'sv', 'nl', 'fi', 'ur', 'ca', 'no', 'ml', None,\n",
       "       'el', 'fa', 'da', 'ar', 'ru', 'km'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Language Column of the Tweets\n",
    "dfP.lang.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Group Lower Rank Langs in Pie Chart\n",
    "def group_lower_ranking_values(column):\n",
    "    pie_counts = dfP.groupby(column).agg('count')\n",
    "    pct_value = pie_counts[lambda dfP: dfP.columns[0]].quantile(.35)\n",
    "    values_below_pct_value = pie_counts[lambda df: df.columns[0]].loc[lambda s: s < pct_value].index.values\n",
    "    def fix_values(row):\n",
    "        if row[column] in values_below_pct_value:\n",
    "            row[column] = 'Other'\n",
    "        return row \n",
    "    pie_grouped = dfP.apply(fix_values, axis=1).groupby(column).agg('count')\n",
    "    return pie_grouped\n",
    "\n",
    "pie_sources = group_lower_ranking_values('lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordArray=dfP[\"text\"].str.split(\" \",expand=True).stack().value_counts()\n",
    "WordDict={\"word\": WordArray.index, \"frequency\":WordArray}\n",
    "#Convert to pandas dataframe\n",
    "dfWord=pd.DataFrame(data=WordDict)\n",
    "#Eliminate nulls\n",
    "dfWord=dfWord[(dfWord['word'] != \"\") == True]\n",
    "dfWord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWord.sort_values(by=['frequency'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWordS=pd.DataFrame(dfWord.groupby('word')['frequency'].sum())\n",
    "dfWordS['word'] = dfWordS.index\n",
    "dfWordS.reset_index(drop=True)\n",
    "dfWordS.sort_values(by='frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordList=dfWordS[\"word\"].values.tolist()\n",
    "str1 = ' '.join(str(e) for e in WordList)\n",
    "\n",
    "# Libraries\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create the wordcloud object\n",
    "wordcloud = WordCloud(width=720, height=720, margin=0).generate(str1)\n",
    " \n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(45,45),facecolor = 'black')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORD COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove some words by list\n",
    "List=[\"rt\", \"ve\", \"bir\",\"ne\",\"oldugunu\",\"kadar\",\"icinde\",\"aylinerk\",\"birakan\",\"de\",\"gosteren\",\"her\",\"der\"]\n",
    "dfWordS = dfWordS[dfWordS['word'].isin(List) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWordS=dfWordS.sort_values(by='frequency', ascending=False).head(20)\n",
    "WordList=dfWordS[\"word\"].values.tolist()\n",
    "print(WordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffname=pd.read_csv(\"/home/ubuntu/TweetswCount.txt\", encoding='utf-8',sep=';',engine='python',usecols=[\"tid\",\"filename\",\"tcreated_at\",\"word\",\"word_count\"])\n",
    "\n",
    "dffname.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffname = dffname[(dffname['tid'] != \"tid\") == True]\n",
    "df=dffname[[\"tid\",\"tcreated_at\",\"word\",\"word_count\"]]\n",
    "df=df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tcreated_at'] = pd.to_datetime(df['tcreated_at'])\n",
    "df['word_count']=pd.to_numeric(df['word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['tcreated_at'].dt.to_period('D')\n",
    "df = df.set_index('day')\n",
    "#df = df[df.index < '2018-06-07']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['word','day'])['word_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "font = {'weight': 'normal',\n",
    "        'size': 25,\n",
    "        }\n",
    "fig, ax = plt.subplots(figsize=(30,15))\n",
    "\n",
    "ax.tick_params(direction='out', length=6, width=2, grid_color='r', grid_alpha=0.1,labelsize=15,which =\"both\")\n",
    "plt.title('Word of Tweets By Day',fontdict=font)\n",
    "plt.xlabel('Day', fontdict=font)\n",
    "plt.ylabel('Count of Word', fontdict=font)\n",
    "df.groupby(['day','word']).sum()['word_count'].unstack().plot(ax=ax)\n",
    "leg = ax.legend(loc='upper left', frameon=True,prop={'size':20})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(30,15))\n",
    "ax.tick_params(direction='out', length=6, width=2, grid_color='r', grid_alpha=0.1,labelsize=15,which =\"both\")\n",
    "plt.title('Word of Tweets By Day',fontdict=font)\n",
    "plt.xlabel('Day', fontdict=font)\n",
    "plt.ylabel('Count of Word', fontdict=font)\n",
    "df.groupby(['day','word']).sum()['word_count'].unstack().plot(ax=ax,kind='area')\n",
    "leg = ax.legend(loc='upper left', frameon=True,prop={'size':20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "fig, ax = plt.subplots(figsize=(30,15))\n",
    "ax.tick_params(direction='out', length=6, width=2, grid_color='r', grid_alpha=0.1,labelsize=15,which =\"both\")\n",
    "plt.title('Tweets By Day',fontdict=font)\n",
    "plt.xlabel('Day', fontdict=font)\n",
    "plt.ylabel('Count of Tweets', fontdict=font)\n",
    "z=df.groupby(['day']).count()['tid']\n",
    "z.plot(ax=ax,kind='area')\n",
    "leg = ax.legend(loc='upper left', frameon=True,prop={'size':20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
